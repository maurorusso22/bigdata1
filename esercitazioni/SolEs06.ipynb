{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyMApqpsLMRiUMaxZ0B4Vva1"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["# Exercise 1\n","\n","1. Compute the match-based similarity, cosine similarity and the Jaccard coefficient, between the two sets {A,B,C} and {A,C,D,E}.\n","\n","2. Compute the Edit distance, and LCSS similarity between (a) ababcabc and babcbc (b) cbacbacba and acbacbacb.\n","\n","3. Compute the cosine measure using the raw frequencies between the following two sentences: (a) “The sly fox jumped over the lazy dog.” and (b) “The dog jumped at the intruder.”\n"],"metadata":{"id":"ffY0qT8LJCyF"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"uwmbUfHTI-_M"},"outputs":[],"source":["# Implementazione di Francesco Di Liberti\n","from scipy.linalg import norm\n","\n","a = {'A', 'B', 'C'}\n","b = {'A', 'C', 'D', 'E'}\n","\n","union = a.union(b)\n","print(f'a U b = {union}')\n","#Match-based\n","avect = [1 if x in a else 0 for x in union]\n","bvect = [1 if x in b else 0 for x in union]\n","print(avect, bvect)\n","\n","s = 0\n","for i in range(len(union)):\n","  if avect[i] == bvect[i] and avect[i]== 1:\n","    s += 1\n","print(f'Match-Based Similarity = {s}')\n","\n","#Cosine similarity\n","s_cosine = s/(norm(avect)*norm(bvect))\n","print(f'Cosine Similarity = {s_cosine}')\n","\n","#Jaccard\n","jaccard = len(a.intersection(b))/len(union)\n","print(f'Jaccard Similarity = {jaccard}')"]},{"cell_type":"code","source":["# Implementazione di Francesco Di Liberti\n","import numpy as np\n","def edit(x,y, del_cost, ins_cost, rep_cost):\n","  m = len(x)+1\n","  n = len(y) +1\n","  edit = np.zeros((m, n))\n","  for i in range(m):\n","    edit[i][0] = i * del_cost\n","  for j in range(1, n):\n","    edit[0][j] = j * ins_cost\n","\n","  for i in range(1, m):\n","    for j in range(1, n):\n","      edit[i, j] = min(edit[i-1, j] + del_cost, edit[i, j-1] + ins_cost, edit[i-1, j-1] + (0 if x[i-1] == y[j-1] else rep_cost))\n","\n","  return edit[m-1,n-1]\n","\n","def lcss(x,y):\n","  m = len(x) + 1\n","  n = len(y) + 1\n","  lcss = np.zeros((m,n))\n","\n","  for i in range(1 ,m):\n","    for j in range(1, n):\n","      if(x[i-1] == y[j-1]):\n","        lcss[i,j] = lcss[i-1, j-1] + 1\n","      else:\n","        lcss[i,j] = max(lcss[i-1, j], lcss[i, j-1])\n","\n","  return lcss[m-1,n-1]"],"metadata":{"id":"f4_JHPtrlN21"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["del_cost = 1;\n","ins_cost = 1;\n","rep_cost = 2;\n","\n","s1 = 'ababcabc'\n","s2 = 'babcbc'\n","print(f'edit({s1}, {s2} = {edit(s1, s2, del_cost, ins_cost, rep_cost)})')\n","print(f'lcss({s1}, {s2} = {lcss(s1, s2)})')\n","\n","s1 = 'cbacbacba'\n","s2 = 'acbacbacb'\n","print(f'edit({s1}, {s2} = {edit(s1, s2, del_cost, ins_cost, rep_cost)})')\n","print(f'lcss({s1}, {s2} = {lcss(s1, s2)})')\n"],"metadata":{"id":"RAfcLfQHlpVj"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Calcolo distanza coseno fra due frasi\n","# Implementazione di Francesco Di Liberti\n","from collections import Counter\n","import math\n","\n","def calculate_norm(counter):\n","    return math.sqrt(sum(val**2 for val in counter.values()))\n","\n","sent_a = 'The sly fox jumped over the lazy dog'\n","sent_b = 'The dog jumped at the intruder'\n","\n","#Creo le liste con le singole parole delle due frasi\n","lista_a = [x.lower() for x in sent_a.split()]\n","lista_b = [x.lower() for x in sent_b.split()]\n","\n","#creo un insieme con tutte le parole\n","all_keys = set(lista_a).union(set(lista_b))\n","\n","#inizializzo due counter a 0 con tutte le parole presenti nelle 2 frasi\n","freq_a, freq_b = Counter(), Counter()\n","\n","#aggiorno la frequenza per ottenere la frequenza delle parole nelle frasi\n","freq_a.update(lista_a)\n","freq_b.update(lista_b)\n","\n","prod_scal = sum(freq_a[key] * freq_b[key] for key in all_keys)\n","\n","norm_a, norm_b = calculate_norm(freq_a), calculate_norm(freq_b)\n","\n","cosine_measure = prod_scal / (norm_a * norm_b)\n","print(cosine_measure)"],"metadata":{"id":"ujhcM7u5nQ0m"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["freq_a['cat']"],"metadata":{"id":"bvJhlnfb2beT"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Exercise 2\n","Write a function to compute the edit distance."],"metadata":{"id":"OPyb16HZKxfN"}},{"cell_type":"code","source":["# fatto nell'esercizio precedente"],"metadata":{"id":"A3Y6XLqVK-LN"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Exercise 3\n","Download the KDD Cup Network Intrusion Data Set for the UCI Machine Learning Repository. Create a data set containing only the categorical attributes. Compute the nearest neighbor for each data point using the (a) Match measure, and (b) Inverse Occurrence Frequency Measure.\n","\n","http://www.lacascia.it/bd2/_kddcup/task.html\n","\n","http://www.lacascia.it/bd2/_kddcup/kddcup.names"],"metadata":{"id":"iXDhGaL2K_FF"}},{"cell_type":"code","source":["import pandas as pd\n","import numpy as np\n","\n","labels=list(range(1, 42))+['class']\n","\n","df = pd.read_csv('http://www.lacascia.it/bd2/_kddcup/kddcup.data_10_percent_corrected.csv', names=labels)\n","\n","print(df.shape)"],"metadata":{"id":"X603JPaYLDgy"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["df"],"metadata":{"id":"uvfCzNCmYL1I"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# frequenza delle classi presenti nel dataset\n","df.iloc[:, 41].value_counts()"],"metadata":{"id":"A_nmBYOvNyCP"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# In base a quanto scritto in http://www.lacascia.it/bd2/_kddcup/kddcup.names\n","# creo i dataframe coi soli categorici, numerici e classi target\n","df_cat = df.iloc[:, [1, 2, 3, 11, 20, 21]]\n","print(df_cat.shape)"],"metadata":{"id":"mCIzgGZEvQVs"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# dataframe coi soli numerici\n","num = list(set(range(41))-{1, 2, 3, 11, 20, 21})\n","df_num = df.iloc[:, num]\n","print(df_num.shape)"],"metadata":{"id":"UIMupYorwG6Q"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Estraggo il target e metto ad attack. tutte le classi diverse da normal.\n","df_target = df.iloc[:, 41].to_numpy(copy=True)\n","print(df_target.shape)\n","\n","for i in range(df_target.size):\n","  if df_target[i]!='normal.':\n","    df_target[i]='attack.'"],"metadata":{"id":"VQTZhLKtzLtd"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# verifico il nuovo vettore dei target\n","unique_values, counts = np.unique(df_target, return_counts=True)\n","for value, count in zip(unique_values, counts):\n","    print(f\"{value} occurs {count} times\")"],"metadata":{"id":"I3Xc8KKczabG"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Implementazione di Francesco Di Liberti\n","# Match measure per dati categorici\n","#La distanza è 0 se sono uguali\n","def match_measure(x1, x2):\n","  #match_count = sum(cat1 == cat2 for cat1, cat2 in zip(x1, x2))\n","  match_count = sum(x1 == x2)\n","  match_m = 1 - match_count / len(x1)\n","  return match_m"],"metadata":{"id":"nudcAXeh790D"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Faccio lo split fra train e test\n","from sklearn.model_selection import train_test_split\n","X_train, X_test, y_train, y_test = train_test_split(df_cat, df_target, random_state=11)\n","\n","print(X_train.shape)\n","print(X_test.shape)\n","\n","# Prendo solo parte del dataset per motivi di tempo di calcolo\n","X_train = X_train[:1500]\n","y_train = y_train[:1500]\n","X_test = X_test[:500]\n","y_test = y_test[:500]\n"],"metadata":{"id":"rtv4Y3Eg_yVw"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Calcolo la matrice delle distanze per il train\n","dist_train = np.zeros((X_train.shape[0], X_train.shape[0]))\n","for i in range(X_train.shape[0]):\n","  for j in range(X_train.shape[0]):\n","    dist_train[i, j] = match_measure(X_train.iloc[i, :], X_train.iloc[j, :])\n","print(f'dist_train: {dist_train.shape}')\n","\n","# Calcolo la matrice delle distanze del test dal train\n","dist_test = np.zeros((X_test.shape[0], X_train.shape[0]))\n","for i in range(X_test.shape[0]):\n","  for j in range(X_train.shape[0]):\n","    dist_test[i, j] = match_measure(X_test.iloc[i, :], X_train.iloc[j, :])\n","print(f'dist_test: {dist_test.shape}')\n","\n","# Costruisco il modello e ne valuto le performance\n","from sklearn.neighbors import KNeighborsClassifier\n","knn = KNeighborsClassifier(n_neighbors=5, metric='precomputed')\n","knn.fit(X=dist_train, y=y_train)\n","\n","print(f'Accuracy: {knn.score(dist_test, y_test):.2%}')"],"metadata":{"id":"iHBXasDIAeOp"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# inverse occurrence frequency measure\n","from collections import Counter\n","\n","# calcolo le frequenze dei simboli nelle diverse features\n","p = []\n","for i in range(6):\n","  p += [Counter(X_train.iloc[:,i])]\n","\n","def inv_occ_freq_dist(x1, x2):\n","  m = 0\n","  for i in range(x1.size):\n","    p2 = (p[i][x1.iat[i]]/p[i].total())\n","    if p2==0:\n","      p2=1\n","    m += (x1.iat[i] == x2.iat[i])/(p2*p2)\n","  return 1/(1+m)"],"metadata":{"id":"5nYsghthUuG9"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Calcolo la matrice delle distanze per il train\n","dist_train = np.zeros((X_train.shape[0], X_train.shape[0]))\n","for i in range(X_train.shape[0]):\n","  for j in range(X_train.shape[0]):\n","    dist_train[i, j] = inv_occ_freq_dist(X_train.iloc[i, :], X_train.iloc[j, :])\n","print(f'dist_train: {dist_train.shape}')\n","\n","# Calcolo la matrice delle distanze del test dal train\n","dist_test = np.zeros((X_test.shape[0], X_train.shape[0]))\n","for i in range(X_test.shape[0]):\n","  for j in range(X_train.shape[0]):\n","    dist_test[i, j] = inv_occ_freq_dist(X_test.iloc[i, :], X_train.iloc[j, :])\n","print(f'dist_test: {dist_test.shape}')\n","\n","# Costruisco il modello e ne valuto le performance\n","from sklearn.neighbors import KNeighborsClassifier\n","knn = KNeighborsClassifier(n_neighbors=5, metric='precomputed')\n","knn.fit(X=dist_train, y=y_train)\n","\n","print(f'Accuracy: {knn.score(dist_test, y_test):.2%}')"],"metadata":{"id":"xSJxdRMedrzt"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["p"],"metadata":{"id":"8AqWBXWvjGWn"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Exercise 4\n","Repeat Exercise 3 using only the quantitative attributes of the data set, and using the $L_p$ norm for values of p = 1, 2, ∞."],"metadata":{"id":"FpPRlOvhL3ED"}},{"cell_type":"code","source":["# Faccio lo split fra train e test\n","from sklearn.model_selection import train_test_split\n","X_train, X_test, y_train, y_test = train_test_split(df_num, df_target, random_state=11)\n","\n","print(X_train.shape)\n","print(X_test.shape)\n","\n","# Prendo solo parte del dataset per analogia ai dati categorici\n","X_train = X_train[:3705]\n","y_train = y_train[:3705]\n","X_test = X_test[:1235]\n","y_test = y_test[:1235]"],"metadata":{"id":"mvs_fKRkMCC2"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Costruisco il modello e ne valuto le performance per p=1\n","from sklearn.neighbors import KNeighborsClassifier\n","knn = KNeighborsClassifier(n_neighbors=5, p=1)\n","knn.fit(X_train, y_train)\n","\n","print(f'Accuracy (1): {knn.score(X_test, y_test):.2%}')"],"metadata":{"id":"pipNZ7pJDk5P"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Costruisco il modello e ne valuto le performance per p=2\n","from sklearn.neighbors import KNeighborsClassifier\n","knn = KNeighborsClassifier(n_neighbors=5, p=2)\n","knn.fit(X_train, y_train)\n","\n","print(f'Accuracy (1): {knn.score(X_test, y_test):.2%}')"],"metadata":{"id":"tjbGrb0KFWPx"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Costruisco il modello e ne valuto le performance per p=inf\n","from sklearn.neighbors import KNeighborsClassifier\n","knn = KNeighborsClassifier(n_neighbors=5, metric='chebyshev')\n","knn.fit(X_train, y_train)\n","\n","print(f'Accuracy (inf): {knn.score(X_test, y_test):.2%}')"],"metadata":{"id":"G7rXBsDZFbMH"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Exercise 5\n","Repeat Exercise 3 using all attributes in the dataset. Use the mixed-attribute function, and different combinations of the categorical and quantitative distance functions of Exercises 3 and 4.\n"],"metadata":{"id":"xnBQ8rRZMC8w"}},{"cell_type":"code","source":[],"metadata":{"id":"Rrkw1NtbMGvk"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Exercise 6\n","\n","IMDB sentiment analysis"],"metadata":{"id":"qG4WcIhgdezc"}},{"cell_type":"code","source":["import pandas as pd\n","\n","labels=['text', 'class']\n","df = pd.read_csv('http://www.lacascia.it/bd2/movie.csv', names=labels)\n","df = df.drop(0)\n","print(df.shape)\n","df.iloc[:,1].value_counts()"],"metadata":{"id":"EzFnBfuAdwg_"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["df"],"metadata":{"id":"3IDsc4sof1BA"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"ttgC4TaOKCqb"},"execution_count":null,"outputs":[]}]}